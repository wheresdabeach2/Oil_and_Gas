{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import os\n",
    "import pandas as pd\n",
    "from pyxlsb import open_workbook\n",
    "import datetime as dt\n",
    "import re\n",
    "\n",
    "\n",
    "#Go to desired directory\n",
    "#os.chdir(\"\") \n",
    "\n",
    "#Find baker hughes website and convert to html\n",
    "url = \"https://rigcount.bakerhughes.com/na-rig-count\"\n",
    "r = requests.get(url)\n",
    "soup = bs(r.text, \"html.parser\")\n",
    "\n",
    "#Find all hyperlinks who's title contains 'Pivot' and pull the first one's address\n",
    "pivot_file = soup.find_all('a', title = re.compile('pivot'))\n",
    "link = pivot_file[0]['href']\n",
    "\n",
    "\n",
    "r = requests.get(link)\n",
    "\n",
    "#Open a workbook and write the binary content into it\n",
    "output = open('baker_hughes_rig_count_binary.xlsb', 'wb')\n",
    "output.write(r.content)\n",
    "output.close()\n",
    "\n",
    "df = []\n",
    "\n",
    "#write the binary workbook to an empty dataframe\n",
    "with open_workbook('baker_hughes_rig_count_binary.xlsb') as wb:\n",
    "    with wb.get_sheet(\"Master Data\") as sheet:\n",
    "        for row in sheet.rows():\n",
    "            df.append([item.v for item in row])\n",
    "\n",
    "df = pd.DataFrame(df[1:], columns=df[0])\n",
    "\n",
    "#Convert Publish date to an excel date format\n",
    "df['PublishDate'] = pd.TimedeltaIndex(df['PublishDate'], unit= 'd') + dt.datetime(1899, 12, 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add the most recent rig count date\n",
    "df['One Week Earlier'] = df['PublishDate'].max() -  pd.to_timedelta(7, unit='d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Caclulate Rig count per basin one week earlier\n",
    "df1 = df[df['One Week Earlier'] == df['PublishDate']].groupby(['Basin'])['RigCount'].agg('sum').reset_index()\n",
    "df1.rename(columns = {\"RigCount\": \"One Week Earlier Rig Total\"},  inplace = True) \n",
    "df = df.merge(df1,on='Basin', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate Rig count per Basin of current week\n",
    "df2 = df[df['PublishDate'] == df['PublishDate'].max()].groupby(['Basin'])['RigCount'].agg('sum').reset_index()\n",
    "df2.rename(columns = {\"RigCount\": \"Newest Rig Total\"},  inplace = True) \n",
    "df = df.merge(df2,on='Basin', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate week over week differential for Basin\n",
    "df['Weekly Change'] = df['Newest Rig Total'] - df['One Week Earlier Rig Total']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Percent Change'] = df['Weekly Change']/df['One Week Earlier Rig Total']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['One Week Earlier'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Write to an excel workbook\n",
    "writer = pd.ExcelWriter('baker_hughes.xlsx', engine='xlsxwriter')\n",
    "df.to_excel(writer, sheet_name='Data', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
